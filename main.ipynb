{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics: **Bank Customer Churn Prediction**\n",
    "\n",
    "Predictive Analytics with *Bank Customer Churn Prediction Datasets*\n",
    "\n",
    "Naufal Mu'afi<br>\n",
    "naufalmuafi@mail.ugm.ac.id\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading/Data Wrangling\n",
    "---\n",
    "\n",
    "Informasi Dataset :\n",
    "\n",
    "Jenis | Keterangan\n",
    "--- | ---\n",
    "Sumber | [Kaggle Dataset : Bank Customer Churn Prediction](https://www.kaggle.com/datasets/shantanudhakadd/bank-customer-churn-prediction/data)\n",
    "Lisensi | Other\n",
    "Kategori | Finance\n",
    "Rating Penggunaan | 9.71\n",
    "Jenis dan Ukuran Berkas | CSV (268 kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.read_csv(\"./data/Churn_Modelling.csv\")\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "---\n",
    "\n",
    "### 2.1 Assesing and Cleaning Data\n",
    "\n",
    "1. What are the types of variables in the dataset?\n",
    "2. How variables distribution in the dataset?\n",
    "3. Are there any missing values?\n",
    "4. Are there any redundant features?\n",
    "5. How about the correlation between features and targets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Variable Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.shape\n",
    "print(f\"The dataset has {churn.shape[0]} rows, and {churn.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNumber of duplications: {churn.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Variable Distribution Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before that, we can drop some unnecessary/dummy feature in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "churn.head()\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can do a classification to the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = []\n",
    "categorical_features = []\n",
    "\n",
    "nfeatures = len(churn.nunique())\n",
    "\n",
    "for i in range(nfeatures):\n",
    "  feature_uniqueness = churn.nunique()\n",
    "  \n",
    "  if feature_uniqueness.values[i] <= 25:\n",
    "    categorical_features.append(feature_uniqueness.index[i])\n",
    "  else:\n",
    "    numerical_features.append(feature_uniqueness.index[i])\n",
    "\n",
    "print(f\"Numerical Features: {numerical_features}\")\n",
    "print(f\"Categorical Features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Handle Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4. Handle The Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(20, 15))\n",
    "\n",
    "for row in range(nrows):\n",
    "  for col in range(ncols):\n",
    "    column = numerical_features[row*ncols + col]\n",
    "    \n",
    "    sns.boxplot(x=churn[column], ax=ax[row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = churn[numerical_features].quantile(0.25)\n",
    "Q3 = churn[numerical_features].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "\n",
    "# # creating a mask for outliers\n",
    "outlier_mask = ((churn[numerical_features] < (Q1 - 1.5*IQR)) | (churn[numerical_features] > (Q3 + 1.5*IQR))).any(axis=1)\n",
    "\n",
    "# #filtering out rows with outliers\n",
    "churn = churn[~outlier_mask]\n",
    "\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(20, 15))\n",
    "\n",
    "for row in range(nrows):\n",
    "  for col in range(ncols):\n",
    "    column = numerical_features[row*ncols + col]\n",
    "    \n",
    "    sns.boxplot(x=churn[column], ax=ax[row, col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Univariate Analysis for Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Geography Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Gender Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Tenure Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Num of Product Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 Has Credit Card Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 Is Active Member Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 5\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.7 Exited Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6\n",
    "feature = categorical_features[index]\n",
    "count = churn[feature].value_counts()\n",
    "percent = 100*churn[feature].value_counts(normalize=True)\n",
    "df = pd.DataFrame({'sample total':count, 'percentage':percent.round(1)})\n",
    "print(df)\n",
    "\n",
    "# Plotting the bar chart\n",
    "ax = count.plot(kind='bar', title=feature)\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'{feature} Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adding data labels on each bar\n",
    "for i, v in enumerate(count):\n",
    "    ax.text(i, v + 0.5, f'{percent.iloc[i]:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Univariate Analysis for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn[numerical_features].hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = categorical_features.copy()\n",
    "cat_features.remove('Exited')\n",
    "\n",
    "for col in cat_features:\n",
    "  sns.catplot(x=col, y='Exited', kind='bar', dodge=False, height=4, aspect=3, data=churn, palette=\"Set3\")\n",
    "  plt.title(f\"Average 'Exited' Relative to {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing relationships between numerical features\n",
    "sns.pairplot(churn, diag_kind = 'kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target to Each Numerical Features Corresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(20, 15))\n",
    "\n",
    "for row in range(nrows):\n",
    "  for col in range(ncols):\n",
    "    column = numerical_features[row*ncols + col]\n",
    "    \n",
    "    sns.barplot(x=churn['Exited'], y=churn[column], ax=ax[row, col], palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Category Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = pd.get_dummies(churn, columns=['Geography', 'Gender'], drop_first=True, dtype=np.int8)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "corr_matrix = churn.corr()\n",
    "\n",
    "sns.heatmap(data=corr_matrix,\n",
    "            xticklabels=corr_matrix.columns,\n",
    "            yticklabels=corr_matrix.columns,\n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            linewidths=0.5)\n",
    "\n",
    "plt.title('Correlation Matrix of The Dataset', fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn.drop(['Exited'], axis=1)\n",
    "y = churn['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=123,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "print(f'Total # of sample in whole dataset: {len(X)}')\n",
    "print(f'Total # of sample in train dataset: {len(X_train)}')\n",
    "print(f'Total # of sample in test dataset: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = list(X_train.columns)\n",
    "\n",
    "for col in features:\n",
    "    X_train[col] = scaler.fit_transform(X_train[col].to_numpy().reshape(-1,1))\n",
    "    X_test[col] = scaler.transform(X_test[col].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numerical_features].describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataframe for model analysis\n",
    "models = pd.DataFrame(index=['train_acc', 'test_acc'],\n",
    "                      columns=['KNN', 'LogisticRegression', 'SVC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 K-Nearest Neighbourhood Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "models.loc['train_acc', 'knn'] = accuracy_score(y_pred=knn.predict(X_train), y_true=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=123)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "models.loc['train_acc', 'LogisticRegression'] = accuracy_score(y_pred=log_reg.predict(X_train), y_true=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Support Vector Classifier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=2.0, kernel='rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "models.loc['train_acc', 'SVC'] = accuracy_score(y_pred=svc.predict(X_train), y_true=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'LogisticRegression', 'SVC'])\n",
    "model_dict = {'KNN': knn, 'LogisticRegression':log_reg, 'SVC':svc}\n",
    "\n",
    "# calculate MSE for each algorithm in train and test dataset\n",
    "for name, model in model_dict.items():\n",
    "  acc.loc[name, 'train'] = accuracy_score(y_true=y_train, y_pred=model.predict(X_train))\n",
    "  acc.loc[name, 'test'] = accuracy_score(y_true=y_test, y_pred=model.predict(X_test))\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "acc.sort_values(by='test', ascending=True).plot(kind='barh', ax=ax, zorder=3)\n",
    "ax.grid(zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = X_test.iloc[:5].copy()\n",
    "pred_dict = {'y_true':y_test[:5]}\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "  pred_dict['prediction_'+name] = model.predict(prediction).round(1)\n",
    "\n",
    "pd.DataFrame(pred_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
